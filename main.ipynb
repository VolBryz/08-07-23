{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db465b47",
   "metadata": {},
   "source": [
    "## Тема 13. Сегментация изображений с текстом:\n",
    "\n",
    "### 1) Алгоритмы автоматического поворота изображения текста, чтобы текст был горизонтальным;\n",
    "\n",
    "### 2) Удаление шума с изображения с текстом;\n",
    "\n",
    "### 3) Нарезание изображения с текстом на символы, которые потом будут отправляться в нейронную сеть для распознавания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe92556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import Output\n",
    "import pytesseract\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb4392",
   "metadata": {},
   "source": [
    "### 1) Алгоритмы автоматического поворота изображения текста, чтобы текст был горизонтальным;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1a6b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf69bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#почти рабочий чистый алгоритм Хафа\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def hough_transform(image):\n",
    "    # Dimensions of the image\n",
    "    height, width = len(image), len(image[0])\n",
    "\n",
    "    # List of detected lines. Each line is represented as a tuple (rho, theta).\n",
    "    lines = []\n",
    "\n",
    "    # Range of possible rho values\n",
    "    rho_max = int((height**2 + width**2)**0.5)  # diagonal length of the image\n",
    "    rho_values = np.linspace(-rho_max, rho_max, int(rho_max * 2.0))\n",
    "\n",
    "\n",
    "    # Range of possible theta values (in degrees)\n",
    "    theta_values = np.deg2rad(np.arange(0.0, 180.0, 0.5))  # step size of 0.5 degrees\n",
    "\n",
    "\n",
    "    # Initialize the accumulator\n",
    "    accumulator = np.zeros((len(rho_values), len(theta_values)))\n",
    "\n",
    "    # For each pixel in the image\n",
    "    for x in range(height):\n",
    "        for y in range(width):\n",
    "            # If the pixel is part of an edge\n",
    "            if image[x][y] != 0:\n",
    "                # For each possible theta value\n",
    "                for theta_idx, theta in enumerate(theta_values):\n",
    "                    # Calculate the corresponding rho value\n",
    "                    rho = x * np.cos(theta) + y * np.sin(theta)\n",
    "                    # Find the rho index that is closest to the calculated rho\n",
    "                    rho_idx = np.argmin(np.abs(rho_values - rho))\n",
    "                    # Increment the corresponding cell in the accumulator\n",
    "                    accumulator[rho_idx][theta_idx] += 1\n",
    "\n",
    "    # Find the maximum value in the accumulator\n",
    "    max_value = np.max(accumulator)\n",
    "\n",
    "    # For each cell in the accumulator\n",
    "    for rho_idx in range(len(rho_values)):\n",
    "        for theta_idx in range(len(theta_values)):\n",
    "            # If the value in the cell is high enough\n",
    "            if accumulator[rho_idx][theta_idx] > max_value * 0.5:  # threshold is 50% of the maximum value\n",
    "                # Add the corresponding line to the list of detected lines\n",
    "                lines.append((rho_values[rho_idx], np.rad2deg(theta_values[theta_idx])))\n",
    "\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "838c7f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.5161290322580641, 90.5),\n",
       " (-0.5161290322580641, 91.0),\n",
       " (-0.5161290322580641, 91.5),\n",
       " (-0.5161290322580641, 92.0),\n",
       " (-0.5161290322580641, 92.5),\n",
       " (-0.5161290322580641, 93.0),\n",
       " (-0.5161290322580641, 93.5),\n",
       " (-0.5161290322580641, 94.0),\n",
       " (-0.5161290322580641, 94.5),\n",
       " (-0.5161290322580641, 95.0),\n",
       " (-0.5161290322580641, 95.5),\n",
       " (-0.5161290322580641, 96.00000000000001),\n",
       " (-0.5161290322580641, 96.5),\n",
       " (-0.5161290322580641, 97.0),\n",
       " (0.5161290322580641, 83.5),\n",
       " (0.5161290322580641, 84.0),\n",
       " (0.5161290322580641, 84.5),\n",
       " (0.5161290322580641, 85.0),\n",
       " (0.5161290322580641, 85.5),\n",
       " (0.5161290322580641, 86.0),\n",
       " (0.5161290322580641, 86.5),\n",
       " (0.5161290322580641, 87.0),\n",
       " (0.5161290322580641, 87.5),\n",
       " (0.5161290322580641, 88.0),\n",
       " (0.5161290322580641, 88.5),\n",
       " (0.5161290322580641, 89.0),\n",
       " (0.5161290322580641, 89.5),\n",
       " (0.5161290322580641, 90.0)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough_transform('Screenshot_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b58c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рисует одну линию, определяющую направление наклона текста\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('Screenshot_2.png')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply edge detection method\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize = 3)\n",
    "\n",
    "# Apply Hough Line Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "\n",
    "# Iterate over the output lines and draw them on the image\n",
    "for rho, theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 10000*(-b))\n",
    "    y1 = int(y0 + 10000*(a))\n",
    "    x2 = int(x0 - 10000*(-b))\n",
    "    y2 = int(y0 - 10000*(a))\n",
    "\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Save the image\n",
    "cv2.imwrite('houghlines.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "169161a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"Screenshot_1.png\")\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply edge detection method\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Apply Hough Line Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=200)\n",
    "\n",
    "# Calculate line length based on image dimensions\n",
    "height, width = image.shape[:2]\n",
    "line_length = int(np.sqrt(height**2 + width**2))\n",
    "\n",
    "# Draw the lines on the image\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + line_length * (-b))\n",
    "    y1 = int(y0 + line_length * (a))\n",
    "    x2 = int(x0 - line_length * (-b))\n",
    "    y2 = int(y0 - line_length * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Text Lines\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ecad87e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# рисовка кучи линий \n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "    \n",
    "def indicar_lines(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edge detection method\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Apply Hough Line Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=200)\n",
    "\n",
    "    # Calculate line length based on image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "    line_length = int(np.sqrt(height**2 + width**2))\n",
    "\n",
    "    # Draw the lines on the image\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + line_length * (-b))\n",
    "        y1 = int(y0 + line_length * (a))\n",
    "        x2 = int(x0 - line_length * (-b))\n",
    "        y2 = int(y0 - line_length * (a))\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Calculate and print the slope in degrees\n",
    "        slope_degrees = theta * (180 / np.pi)\n",
    "        print(f\"Slope of line: {slope_degrees} degrees\")\n",
    "    \n",
    "    output = 'hugeline_' + image_path\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fbd5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def rotate_image(image_input):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_input)\n",
    "    source = cv2.imread(image_input)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edgedd detection method\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Apply Hough Line Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=200)\n",
    "\n",
    "    # Calculate line length based on image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "    line_length = int(np.sqrt(height**2 + width**2))\n",
    "\n",
    "    # Initialize a variable to accumulate the sum of all slope angles\n",
    "    total_degrees = 0\n",
    "\n",
    "    # Draw the lines on the image\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + line_length * (-b))\n",
    "        y1 = int(y0 + line_length * (a))\n",
    "        x2 = int(x0 - line_length * (-b))\n",
    "        y2 = int(y0 - line_length * (a))\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Calculate the slope in degrees and add it to the total\n",
    "        slope_degrees = theta * (180 / np.pi)\n",
    "        total_degrees += slope_degrees\n",
    "\n",
    "    # Calculate the average slope\n",
    "    average_slope_degrees = total_degrees / len(lines)\n",
    "    print(f\"Average slope: {average_slope_degrees} degrees\")\n",
    "\n",
    "    # Calculate the new image size\n",
    "    diagonal = int(math.sqrt(height**2 + width**2))\n",
    "    new_height = int(diagonal)\n",
    "    new_width = int(diagonal)\n",
    "\n",
    "    # Create a new image with white background\n",
    "    new_image = np.ones((new_height, new_width, 3), dtype=np.uint8)\n",
    "    new_image.fill(255)\n",
    "\n",
    "    # Paste the source image into the center of the new image\n",
    "    x_offset = (new_width - width) // 2\n",
    "    y_offset = (new_height - height) // 2\n",
    "    new_image[y_offset:y_offset+height, x_offset:x_offset+width] = source\n",
    "\n",
    "    # Get the new center\n",
    "    new_center = (new_width // 2, new_height // 2)\n",
    "\n",
    "    # Get the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(new_center, average_slope_degrees-90, 1)\n",
    "\n",
    "    # Perform the rotation\n",
    "    rotated_image = cv2.warpAffine(new_image, rotation_matrix, (new_width, new_height))\n",
    "    \n",
    "    edit_image = 'rotated_' + image_input \n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(edit_image, rotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09b42ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average slope: 110.00537478448256 degrees\n"
     ]
    }
   ],
   "source": [
    "rotate_image(\"Screenshot_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ca8b0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def rotate_image(image_input):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_input)\n",
    "    source = cv2.imread(image_input)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply edge detection method\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Apply Hough Line Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=200)\n",
    "\n",
    "    # Calculate line length based on image dimensions\n",
    "    height, width = image.shape[:2]\n",
    "    line_length = int(np.sqrt(height**2 + width**2))\n",
    "\n",
    "    # Initialize a list to hold all slope angles\n",
    "    slope_degrees_list = []\n",
    "\n",
    "    # Draw the lines on the image\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + line_length * (-b))\n",
    "        y1 = int(y0 + line_length * (a))\n",
    "        x2 = int(x0 - line_length * (-b))\n",
    "        y2 = int(y0 - line_length * (a))\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Calculate the slope in degrees and add it to the list\n",
    "        slope_degrees = theta * (180 / np.pi)\n",
    "        slope_degrees_list.append(slope_degrees)\n",
    "\n",
    "    # Calculate the IQR\n",
    "    Q1 = np.percentile(slope_degrees_list, 25)\n",
    "    Q3 = np.percentile(slope_degrees_list, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Filter out the outliers\n",
    "    filtered_slope_degrees_list = [x for x in slope_degrees_list if (Q1 - 1.5 * IQR < x < Q3 + 1.5 * IQR)]\n",
    "\n",
    "    # Calculate the average slope\n",
    "    average_slope_degrees = np.mean(filtered_slope_degrees_list)\n",
    "    print(f\"Average slope: {average_slope_degrees} degrees\")\n",
    "\n",
    "    # Calculate the new image size\n",
    "    diagonal = int(math.sqrt(height**2 + width**2))\n",
    "    new_height = int(diagonal)\n",
    "    new_width = int(diagonal)\n",
    "\n",
    "    # Create a new image with white background\n",
    "    new_image = np.ones((new_height, new_width, 3), dtype=np.uint8)\n",
    "    new_image.fill(255)\n",
    "\n",
    "    # Paste the source image into the center of the new image\n",
    "    x_offset = (new_width - width) // 2\n",
    "    y_offset = (new_height - height) // 2\n",
    "    new_image[y_offset:y_offset+height, x_offset:x_offset+width] = source\n",
    "\n",
    "    # Get the new center\n",
    "    new_center = (new_width // 2, new_height // 2)\n",
    "\n",
    "    # Get the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(new_center, average_slope_degrees-90, 1)\n",
    "\n",
    "    # Perform the rotation\n",
    "    rotated_image = cv2.warpAffine(new_image, rotation_matrix, (new_width, new_height))\n",
    "    \n",
    "    edit_image = 'rotated_' + image_input \n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(edit_image, rotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6e6fc589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average slope: 9.232558164810207 degrees\n"
     ]
    }
   ],
   "source": [
    "rotate_image(\"editA_photo_2023-07-06_23-09-16.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3676982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average slope: 9.294117688062634 degrees\n"
     ]
    }
   ],
   "source": [
    "rotate_image('Screenshot_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "678e2a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average slope: 66.08064499883295 degrees\n",
      "Average slope: 122.571431006548 degrees\n"
     ]
    }
   ],
   "source": [
    "rotate_image(\"Screenshot_5.png\")\n",
    "rotate_image(\"Screenshot_6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b2d7d092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 65.00000067042492 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.00000183661733 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n",
      "Slope of line: 66.99999617262056 degrees\n"
     ]
    }
   ],
   "source": [
    "indicar_lines(\"Screenshot_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2a1a2d53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n",
      "Slope of line: 123.00000000769224 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n",
      "Slope of line: 122.00000567168901 degrees\n"
     ]
    }
   ],
   "source": [
    "indicar_lines(\"Screenshot_6.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "877c93e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.000000250447817 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n",
      "Slope of line: 7.999999938029066 degrees\n",
      "Slope of line: 9.99999970909292 degrees\n"
     ]
    }
   ],
   "source": [
    "indicar_lines(\"editC_photo_2023-07-06_23-09-16.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ba019",
   "metadata": {},
   "source": [
    "### 2) Удаление шума с изображения с текстом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27db0839",
   "metadata": {},
   "source": [
    "To remove digital noise from images with text, there are several methods and tools available. Here are some steps and considerations to help you achieve this:\n",
    "\n",
    "**Image Smoothing**: One approach to removing noise from images is by applying image smoothing techniques. This involves reducing the high-frequency components in the image, which are often associated with noise. You can adjust the degree of smoothing to control the intensity of the noise removal. However, be cautious when setting high smoothing values, as it may result in an unnatural, plastic-like appearance for brightness noise or color changes for color noise.\n",
    "\n",
    "**Noise Suppression**: On grayscale images, where there is no color component, you only need to adjust the parameters for brightness noise suppression. The histogram of the image can help you determine which parameter to modify for the best results. It characterizes the noise level of the original image and remains unchanged when adjusting the settings on the control panel.\n",
    "\n",
    "**Quality and Noise Level**: Some tools provide additional parameters such as quality and noise level. The quality parameter reduces the number of color spots during noise smoothing, but it significantly increases processing time. The noise level parameter determines what to consider as noise (brightness or color) and what to treat as important image details. Be cautious with high noise level values, as they may result in the smoothing of fine image details.\n",
    "\n",
    "**Sensor Level Noise Suppression**: To prevent or reduce digital noise at the sensor level, techniques such as using larger pixels and micro-lenses that are closely packed together can be employed. Color filters that allow a higher percentage of light can also be used. However, it's important to note that using color filters may negatively impact color reproduction.\n",
    "\n",
    "**Exposure Time**: Longer exposure times can contribute to higher levels of noise, especially due to the increase in thermal noise from the electronic components. To mitigate this, consider reducing the exposure time while maintaining the same amount of light reaching the sensor.\n",
    "\n",
    "**Interpolation**: Interpolation methods are used to handle defective pixels in image sensors. These methods replace the defective pixel with neighboring pixels or calculate a value based on surrounding elements. While interpolation helps mitigate the impact of defective pixels, it can affect image sharpness and introduce artifacts.\n",
    "\n",
    "**Post-processing**: Digital noise can be further reduced through post-processing techniques. One common approach is to average the pixel brightness within a group of pixels that are considered similar. However, this can result in a loss of image detail and a \"softer\" appearance. It's important to note that false details may also appear in the image due to the algorithm's interpretation of similarity. Careful parameter tuning is necessary to achieve the desired noise reduction without sacrificing image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef3aab",
   "metadata": {},
   "source": [
    "#### solution using the OpenCV and the PyTesseract library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac99fb8f",
   "metadata": {},
   "source": [
    "Method 1: Background Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "88b9d0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "def noise_removeA(im):\n",
    "    image = cv2.imread(im)\n",
    "    # Convert the image to grayscale\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Define the structuring element\n",
    "    se = cv2.getStructuringElement(cv2.MORPH_RECT , (8,8))\n",
    "    # Dilate the image\n",
    "    bg = cv2.morphologyEx(image, cv2.MORPH_DILATE, se)\n",
    "    # Divide the image by the background\n",
    "    out_gray = cv2.divide(image, bg, scale=255)\n",
    "    # Apply Otsu's thresholding\n",
    "    out_binary = cv2.threshold(out_gray, 0, 255, cv2.THRESH_OTSU)[1]\n",
    "    cv2.imwrite('editA_' + im,  out_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ec14817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_removeA(\"photo_2023-07-06_23-09-16.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72524790",
   "metadata": {},
   "source": [
    "Method 2: Division Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a74a6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def noise_removeB(im):\n",
    "    img = cv2.imread(im)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blur = cv2.GaussianBlur(gray, (0,0), sigmaX=33, sigmaY=33)\n",
    "\n",
    "    # Divide the original image by the blurred image\n",
    "    divide = cv2.divide(gray, blur, scale=255)\n",
    "\n",
    "    # Apply Otsu's thresholding\n",
    "    thresh = cv2.threshold(divide, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Define the structuring element\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    # Apply morphological operations\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    cv2.imwrite('editB_' + im,  morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "236b97ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_removeB(\"photo_2023-07-06_23-09-16.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3475a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removeC(im):\n",
    "    import cv2\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(im, 0)\n",
    "\n",
    "    # Apply median filter\n",
    "    filtered_image = cv2.medianBlur(image, 5)  # 5 is the kernel size\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite('editC_' + im, filtered_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fd647fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_removeC('photo_2023-07-06_23-09-16.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3018bfc",
   "metadata": {},
   "source": [
    "### 3) Нарезание изображения с текстом на символы, которые потом будут отправляться в нейронную сеть для распознавания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39866b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def highlight_letters(image_path, output_path):\n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    pixels = image.load()\n",
    "\n",
    "\n",
    "    marked_pixels = []\n",
    "    for i in range(image.width):\n",
    "        for j in range(image.height):\n",
    "            if pixels[i, j] < 128:\n",
    "                marked_pixels.append((i, j))\n",
    "\n",
    "\n",
    "    groups = []\n",
    "    current_group = [marked_pixels[0]]\n",
    "    for pixel in marked_pixels[1:]:\n",
    "        if abs(pixel[0] - current_group[-1][0]) <= 1 and abs(pixel[1] - current_group[-1][1]) <= 1:\n",
    "            current_group.append(pixel)\n",
    "        else:\n",
    "            groups.append(current_group)\n",
    "            current_group = [pixel]\n",
    "    groups.append(current_group)\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for group in groups:\n",
    "        min_x = min(pixel[0] for pixel in group)\n",
    "        max_x = max(pixel[0] for pixel in group)\n",
    "        min_y = min(pixel[1] for pixel in group)\n",
    "        max_y = max(pixel[1] for pixel in group)\n",
    "        draw.rectangle([(min_x, min_y), (max_x, max_y)], outline=\"red\")\n",
    "\n",
    "    image.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d624bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_letters(\"rotated_Screenshot_4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571cb43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
